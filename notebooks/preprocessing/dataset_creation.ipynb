{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ec18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.spatial.distance import euclidean\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43549077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets\n",
    "\n",
    "base_path = 'C:/Users/Mikel/Desktop/Archivos/Estudios/Ciencia de Datos/TFM/Tercera iteración'\n",
    "air_data = base_path + '/air_quality_dict.pickle'\n",
    "nearest_traffic_data = base_path + '/nearest_dict.pickle'\n",
    "nearest_air_data = base_path + '/nearest_air_dict.pickle'\n",
    "geo_data = base_path + '/geo_dict.pickle'\n",
    "traffic_data = base_path + '/traffic_dict.pickle'\n",
    "\n",
    "with open(air_data, 'rb') as handle:\n",
    "    air_dict = pickle.load(handle)\n",
    "\n",
    "with open(nearest_traffic_data, 'rb') as handle:\n",
    "    nearest_traffic_dict = pickle.load(handle)\n",
    "    \n",
    "with open(nearest_air_data, 'rb') as handle:\n",
    "    nearest_air_dict = pickle.load(handle)\n",
    "    \n",
    "with open(geo_data, 'rb') as handle:\n",
    "    geo_dict = pickle.load(handle)\n",
    "    \n",
    "with open(traffic_data, 'rb') as handle:\n",
    "    traffic_dict = pickle.load(handle)\n",
    "    \n",
    "meteo_path ='C:/Users/Mikel/Desktop/Archivos/Estudios/Ciencia de Datos/TFM/Tercera iteración/meteo.csv'\n",
    "meteo_df = pd.read_csv(meteo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40dd7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a dict with the desired daterange\n",
    "\n",
    "air_dict_dates = {}\n",
    "for key, df in air_dict.items():\n",
    "    df = df.loc['2021-07-01':'2022-06-30']\n",
    "    air_dict_dates[key] = df\n",
    "    \n",
    "# We filter dates from the meteo dataframe to fit the desired daterange\n",
    "    \n",
    "meteo_df = meteo_df.set_index('time')\n",
    "meteo_dates = meteo_df.loc['2021-07-01':'2022-07-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96f0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We join traffic data with air quality data\n",
    "\n",
    "complete_dict = {}\n",
    "for key, df in traffic_dict.items():\n",
    "    air_station = nearest_traffic_dict[key]\n",
    "    air_df = air_dict_dates[air_station]\n",
    "    df = pd.concat([df, air_df.reindex(df.index)], axis = 1)\n",
    "    geo_df = geo_dict[key]\n",
    "    for column in geo_df.columns:\n",
    "        col_ = geo_df[column].values.tolist()\n",
    "        col = col_ * len(df.index)\n",
    "        df[column] = col\n",
    "    for column in meteo_dates.columns:\n",
    "        df[column] = meteo_dates[column].values\n",
    "    complete_dict[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2cedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition of festivities, weekends and school holidays\n",
    "\n",
    "# Weekends\n",
    "\n",
    "a_station = complete_dict[10498]\n",
    "a_station_i = a_station.index.to_series()\n",
    "weekdays = a_station_i.dt.dayofweek\n",
    "is_weekend = weekdays > 4\n",
    "is_weekend = is_weekend.astype(int)\n",
    "\n",
    "# School holidays & bank holidays\n",
    "\n",
    "index_f = a_station_i.dt.strftime('%Y-%m-%d')\n",
    "fechas_list = index_f.tolist()\n",
    "ver_2021 = pd.date_range('20210701','20210906')\n",
    "hisp_2021 = pd.date_range('20211009','20211012')\n",
    "sant_2021 = pd.date_range('20211030','20211101')\n",
    "cons_2021 = pd.date_range('20211204','20211208')\n",
    "nav_2021 = pd.date_range('20211223','20211231')\n",
    "nav_2022 = pd.date_range('20220101','20220110')\n",
    "carn_2022 = pd.date_range('20220225','20220228')\n",
    "ss_2022 = pd.date_range('20220408','20220418')\n",
    "mad_2022 = pd.date_range('20220430','20220502')\n",
    "ver_2022 = pd.date_range('20220627','20220630')\n",
    "\n",
    "binaries = []\n",
    "dates_list = []\n",
    "holidays = [ver_2021, hisp_2021, sant_2021, cons_2021, nav_2021, nav_2022, carn_2022, ss_2022, mad_2022, ver_2022]\n",
    "for list_ in holidays:\n",
    "    list_ = list_.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n",
    "    for item in list_:\n",
    "        dates_list.append(item)\n",
    "for item in fechas_list:\n",
    "    if item in dates_list:\n",
    "        binaries.append(1)\n",
    "    elif item not in dates_list:\n",
    "        binaries.append(0)\n",
    "        \n",
    "# Combination of both infos\n",
    "\n",
    "holiday_weekends = []\n",
    "weekend_list = is_weekend.values.tolist()\n",
    "for i in range(0, len(weekend_list)):\n",
    "    if weekend_list[i] == 1 or binaries[i] == 1:\n",
    "        holiday_weekends.append(1)\n",
    "    elif weekend_list[i] == 0 or binaries[i] == 0:\n",
    "        holiday_weekends.append(0)\n",
    "\n",
    "# Addition to dict\n",
    "\n",
    "complete_dict_ = {}\n",
    "for key, df in complete_dict.items():\n",
    "    df['holiday'] = holiday_weekends\n",
    "    complete_dict_[key] = df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29185243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the utm coordinates of the stations\n",
    "\n",
    "estaciones_dataset = complete_dict_.keys()\n",
    "estaciones_trafico = pd.read_csv('C:/Users/Mikel/Desktop/estaciones_chamberi.csv')\n",
    "mask = estaciones_trafico['id'].isin(estaciones_dataset)\n",
    "estaciones_trafico = estaciones_trafico[mask]\n",
    "estaciones_trafico = estaciones_trafico[['id', 'utm_x', 'utm_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b2c3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the stations following a series of buffers\n",
    "\n",
    "euclidean_dict = {}\n",
    "estaciones = estaciones_trafico['id'].tolist()\n",
    "trafico_x = estaciones_trafico['utm_x'].tolist()\n",
    "trafico_y = estaciones_trafico['utm_y'].tolist()\n",
    "trafico_coords = list(zip(trafico_x, trafico_y))\n",
    "for i in range(0, len(trafico_coords)):\n",
    "        key = estaciones[i]\n",
    "        station_dict = {}\n",
    "        list_25 = []\n",
    "        list_50 = []\n",
    "        list_100 = []\n",
    "        list_200 = []\n",
    "        list_500 = []\n",
    "        list_1000 = []\n",
    "        for j in range(0, len(trafico_coords)):\n",
    "            dist = euclidean(trafico_coords[i], trafico_coords[j])\n",
    "            if dist > 0 and dist < 25:\n",
    "                list_25.append(estaciones[j])\n",
    "            if dist > 0 and dist < 50:\n",
    "                list_50.append(estaciones[j])\n",
    "            if dist > 0 and dist < 100:\n",
    "                list_100.append(estaciones[j])\n",
    "            if dist > 0 and dist < 200:\n",
    "                list_200.append(estaciones[j])\n",
    "            if dist > 0 and dist < 500:\n",
    "                list_500.append(estaciones[j])\n",
    "            if dist > 0 and dist < 1000:\n",
    "                list_1000.append(estaciones[j])\n",
    "        station_dict[25] = list_25\n",
    "        station_dict[50] = list_50\n",
    "        station_dict[100] = list_100\n",
    "        station_dict[200] = list_200\n",
    "        station_dict[500] = list_500\n",
    "        station_dict[1000] = list_1000\n",
    "        euclidean_dict[key] = station_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f4e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the final complete dict\n",
    "\n",
    "complete_dict_buf = {}\n",
    "for key, df in complete_dict_.items():\n",
    "    buffer_dict = euclidean_dict[key]\n",
    "    for k, l in buffer_dict.items():\n",
    "        if l:\n",
    "            for item in l:\n",
    "                colname = str(k) + '_' + str(item)\n",
    "                traffic_df = complete_dict[item]['intensidad']\n",
    "                traffic_df = traffic_df.rename(colname)\n",
    "                df = pd.concat([df, traffic_df.reindex(df.index)], axis = 1)\n",
    "    complete_dict_buf[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02626fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We export the result to a csv file\n",
    "\n",
    "base_path = 'C:/Users/Mikel/Desktop/Archivos/Estudios/Ciencia de Datos/TFM/Tercera iteración/dataset'\n",
    "for key, df in complete_dict_buf.items():\n",
    "    filename = '/dataset_' + str(key) + '.csv'\n",
    "    filepath = base_path + filename\n",
    "    df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22575768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the keys of the final stations\n",
    "\n",
    "keys = []\n",
    "for key in complete_dict_buf.keys():\n",
    "    keys.append(key)\n",
    "keys_df = pd.DataFrame(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf820b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We export the keys to a separate df\n",
    "\n",
    "file_path = 'C:/Users/Mikel/Desktop/Archivos/Estudios/Ciencia de Datos/TFM/Tercera iteración/keys_df.csv'\n",
    "keys_df.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7cbcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the datasets\n",
    "\n",
    "with open('C:/Users/Mikel/Desktop/Archivos/Estudios/Ciencia de Datos/TFM/Tercera iteración/complete_dict_buf.pickle' \\\n",
    "          , 'wb') as handle:\n",
    "    pickle.dump(complete_dict_buf, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_mikel",
   "language": "python",
   "name": "tfm_mikel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
